{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "FbdwAb6YULXo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8guPwJuyCh42"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import json\n",
        "import pickle\n",
        "import gensim\n",
        "import gensim.downloader as api\n",
        "import torchtext\n",
        "from torch import nn, stack, tensor\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "mHox63fAeLd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "jNUsluvRUQ6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPQEaxwmGy_N",
        "outputId": "b6aac90b-4182-455c-d4d6-059efa4902e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/My Drive/minivqaiust/image_features.pickle\", 'rb') as f:\n",
        "    image_feature = pickle.load(f)\n",
        "\n",
        "with open(\"/content/drive/My Drive/minivqaiust/image_question.json\") as f:\n",
        "      image_question_map = json.load(f)"
      ],
      "metadata": {
        "id": "u5e51vjEFIqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions={}\n",
        "\n",
        "for image_id, question in image_question_map.items():\n",
        "  for q in question:\n",
        "    questions[q[0]] = {'question_text':q[1], 'image_id': str(image_id)}"
      ],
      "metadata": {
        "id": "u9cks--RF-RZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pre proccessing train data\n",
        "df = pd.read_csv(\"/content/drive/My Drive/minivqaiust/train.csv\")\n",
        "\n",
        "train_label=torch.tensor(list(df['label']))\n",
        "train_question=[questions[i]['question_text'] for i in list(df['question_id'])]\n",
        "train_image_feature = [image_feature[questions[i]['image_id']] for i in list(df['question_id'])]"
      ],
      "metadata": {
        "id": "Lb9GSMrnUWyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pre proccessing validation data\n",
        "df = pd.read_csv(\"/content/drive/My Drive/minivqaiust/val.csv\")\n",
        "\n",
        "valid_label=torch.tensor(list(df['label']))\n",
        "valid_question=[questions[i]['question_text'] for i in list(df['question_id'])]\n",
        "valid_image_feature = torch.tensor([image_feature[questions[i]['image_id']] for i in list(df['question_id'])])"
      ],
      "metadata": {
        "id": "tSHUf1qfJJfZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cac0879a-3687-461c-8489-87045a65e3d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-4e22ac001af4>:6: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  valid_image_feature = torch.tensor([image_feature[questions[i]['image_id']] for i in list(df['question_id'])])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pre proccessing test data\n",
        "df = pd.read_csv(\"/content/drive/My Drive/minivqaiust/test.csv\")\n",
        "\n",
        "test_question=[questions[i]['question_text'] for i in list(df['question_id'])]\n",
        "test_image_feature = torch.tensor([image_feature[questions[i]['image_id']] for i in list(df['question_id'])])"
      ],
      "metadata": {
        "id": "3BaYh6IpJKCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Embedding"
      ],
      "metadata": {
        "id": "ftLNcNguLmuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize\n",
        "tokenizer = torchtext.data.utils.get_tokenizer('basic_english')\n",
        "\n",
        "# pre embedding model\n",
        "pre_model = api.load('word2vec-google-news-300')"
      ],
      "metadata": {
        "id": "Y6euHxsSLpB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding layer\n",
        "word_embedding = nn.Embedding(len(pre_model.index_to_key) + 1, len(pre_model.get_vector('hi')))"
      ],
      "metadata": {
        "id": "ZizvAQmtNND1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(input):\n",
        "  return [pre_model.get_index(token, default=-1) + 1 for token in tokenizer(input)]\n",
        "\n",
        "def padify(input):\n",
        "  encoded_input = [encode(x) for x in input]\n",
        "  return stack([nn.functional.pad(tensor(e),(0,15-len(e)),mode='constant',value=0) for e in encoded_input])"
      ],
      "metadata": {
        "id": "u3Bq0d3ZO5D3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# word embedding on train data\n",
        "with torch.no_grad():\n",
        "  train_question_embedding = word_embedding(padify(train_question))"
      ],
      "metadata": {
        "id": "5GzFKGWRO7sN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# word embedding on validation data\n",
        "with torch.no_grad():\n",
        "  valid_question_embedding = word_embedding(padify(valid_question))"
      ],
      "metadata": {
        "id": "fUs0G6nfRREx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# word embedding on test data\n",
        "with torch.no_grad():\n",
        "  test_question_embedding = word_embedding(padify(test_question))"
      ],
      "metadata": {
        "id": "dbTa7eH5RR4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data loader\n"
      ],
      "metadata": {
        "id": "hK7YWW5oRrp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torch.utils.data.TensorDataset(train_question_embedding, torch.tensor(train_image_feature), train_label)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "ntjQN-rjRvh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_dataset = torch.utils.data.TensorDataset(valid_question_embedding, valid_image_feature, valid_label)\n",
        "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "O0ld9shNRvcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "LorGRwwUS62t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VQA(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(type(self), self).__init__()\n",
        "        self.lstm = nn.LSTM(300, 512, num_layers=1).to(device)\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(8192, 128),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Linear(128, 10),\n",
        "            nn.Tanh()\n",
        "        ).to(device)\n",
        "\n",
        "    def forward(self, text, image):\n",
        "        text_features= torch.flatten(self.lstm(text)[0], start_dim=1).to(device)\n",
        "        input = torch.cat([text_features, image], dim=1).to(device)\n",
        "        logits = nn.functional.softmax(self.linear(input), dim=1)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "PsLh9eXGS22Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VQA()"
      ],
      "metadata": {
        "id": "PioQ-viZGI1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and Validation"
      ],
      "metadata": {
        "id": "PspgoaPwG0XD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0004)"
      ],
      "metadata": {
        "id": "kIlaF0DJG1yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validation_loop(model, dataloader):\n",
        "  size = len(dataloader.dataset)\n",
        "  correct = 0\n",
        "  avg_loss = 0\n",
        "  for batch, (text, image, label) in enumerate(dataloader):\n",
        "    prediction = model(text.to(device), image.to(device))\n",
        "    loss = loss_function(prediction, label.to(device))\n",
        "\n",
        "    output = [torch.argmax(p).item() for p in prediction]\n",
        "    correct += (torch.FloatTensor(output) == label).float().sum()\n",
        "    avg_loss += loss.item()\n",
        "\n",
        "  accuracy = correct / len(dataloader.dataset)\n",
        "  return avg_loss, accuracy\n"
      ],
      "metadata": {
        "id": "szrILLfGM0eV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(dataloader, model, loss_function, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    correct = 0\n",
        "    avg_loss = 0\n",
        "    for batch, (text, image, label) in enumerate(dataloader):\n",
        "        prediction = model(text.to(device), image.to(device))\n",
        "        loss = loss_function(prediction, label.to(device))\n",
        "        avg_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        output = [torch.argmax(p).item() for p in prediction]\n",
        "        correct += (torch.FloatTensor(output) == label).float().sum()\n",
        "\n",
        "    avg_loss /= (len(dataloader.dataset) // 64 + 1)\n",
        "    accuracy = correct / len(dataloader.dataset)\n",
        "\n",
        "    val_loss, val_acc = validation_loop(model, valid_dataloader)\n",
        "    print(f\"training / loss: {avg_loss:>7f} | accuracy: {accuracy}\")\n",
        "    print(f\"val / loss: {val_loss:>7f} | accuracy: {val_acc}\")"
      ],
      "metadata": {
        "id": "vy1H-eYUHz7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del pre_model\n",
        "del image_feature\n",
        "del questions\n",
        "del word_embedding\n"
      ],
      "metadata": {
        "id": "lk-X779P0j3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epochs in range(15):\n",
        "    print(f\"Epoch {epochs+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_function, optimizer)"
      ],
      "metadata": {
        "id": "Wa6pvVtLN9td",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9a8cc46-1a2d-4d2e-821f-1250fb96d003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "training / loss: 2.292975 | accuracy: 0.1576923131942749\n",
            "val / loss: 4.555639 | accuracy: 0.2454545497894287\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "training / loss: 2.255680 | accuracy: 0.30128204822540283\n",
            "val / loss: 4.472806 | accuracy: 0.4363636374473572\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "training / loss: 2.238444 | accuracy: 0.3807692229747772\n",
            "val / loss: 4.452094 | accuracy: 0.3909091055393219\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "training / loss: 2.200831 | accuracy: 0.4769230782985687\n",
            "val / loss: 4.385391 | accuracy: 0.5\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "training / loss: 2.162609 | accuracy: 0.5769230723381042\n",
            "val / loss: 4.304508 | accuracy: 0.6000000238418579\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "training / loss: 2.134205 | accuracy: 0.6512820720672607\n",
            "val / loss: 4.265432 | accuracy: 0.6000000238418579\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "training / loss: 2.120522 | accuracy: 0.6243589520454407\n",
            "val / loss: 4.276535 | accuracy: 0.6000000238418579\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "training / loss: 2.120868 | accuracy: 0.6307692527770996\n",
            "val / loss: 4.244634 | accuracy: 0.6636363863945007\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "training / loss: 2.108972 | accuracy: 0.6653845906257629\n",
            "val / loss: 4.227545 | accuracy: 0.6545454263687134\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "training / loss: 2.102177 | accuracy: 0.6935897469520569\n",
            "val / loss: 4.234672 | accuracy: 0.6454545259475708\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "training / loss: 2.101890 | accuracy: 0.7243589758872986\n",
            "val / loss: 4.226001 | accuracy: 0.6727272868156433\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "training / loss: 2.094290 | accuracy: 0.735897421836853\n",
            "val / loss: 4.172756 | accuracy: 0.7454545497894287\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "training / loss: 2.065321 | accuracy: 0.8115384578704834\n",
            "val / loss: 4.188826 | accuracy: 0.7454545497894287\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "training / loss: 2.070626 | accuracy: 0.7884615659713745\n",
            "val / loss: 4.193607 | accuracy: 0.7272727489471436\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "training / loss: 2.071566 | accuracy: 0.7756410241127014\n",
            "val / loss: 4.161270 | accuracy: 0.7454545497894287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "id": "aDIj2e6iPXrW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model(test_question_embedding.to(device), torch.tensor(test_image_feature).to(device))\n",
        "\n",
        "output = np.array([torch.argmax(p).item() for p in prediction], dtype='int64')\n",
        "\n",
        "test_csv = pd.read_csv(\"/content/drive/My Drive/minivqaiust/test.csv\")\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'question_id': sorted(test_csv.index.values),\n",
        "    'label': output\n",
        "})\n",
        "print(df.head())\n",
        "df.to_csv('/content/drive/My Drive//minivqa-version1.csv', index=False)\n"
      ],
      "metadata": {
        "id": "-KVrBVQnPZo2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c479e80-11be-4949-dfd6-738d819a8b39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   question_id  label\n",
            "0            0      7\n",
            "1            1      7\n",
            "2            2      4\n",
            "3            3      7\n",
            "4            4      3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-60-6e64447c9581>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  prediction = model(test_question_embedding.to(device), torch.tensor(test_image_feature).to(device))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/content/drive/My Drive//minivqa-versio1-model.pth')"
      ],
      "metadata": {
        "id": "dKf1nEI1rwlN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}